{"cells":[{"cell_type":"markdown","source":["### Transfer learning in action\n##### Check that we have correct libraries installed"],"metadata":{}},{"cell_type":"code","source":["import tensorflow\nimport keras\nimport h5py\nassert(tensorflow.__version__ == '1.12.0')\nassert(keras.__version__ == '2.2.4')\nassert(h5py.__version__ == '2.7.0')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from &#96;float&#96; to &#96;np.floating&#96; is deprecated. In future, it will be treated as &#96;np.float64 == np.dtype(float).type&#96;.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n</div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["##### Download the flower dataset"],"metadata":{}},{"cell_type":"code","source":["%sh\ncurl -O http://download.tensorflow.org/example_images/flower_photos.tgz\ntar xzf flower_photos.tgz &>/dev/null\ncd flower_photos\nls\npwd"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n 14  218M   14 32.0M    0     0  21.3M      0  0:00:10  0:00:01  0:00:09 21.3M\n 36  218M   36 80.0M    0     0  36.9M      0  0:00:05  0:00:02  0:00:03 36.9M\n 65  218M   65  144M    0     0  45.0M      0  0:00:04  0:00:03  0:00:01 45.0M\n 95  218M   95  208M    0     0  46.6M      0  0:00:04  0:00:04 --:--:-- 46.6M\n100  218M  100  218M    0     0  48.5M      0  0:00:04  0:00:04 --:--:-- 50.0M\ndaisy\ndandelion\nLICENSE.txt\nroses\nsunflowers\ntulips\n/databricks/driver/flower_photos\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["img_dir = 'file:/databricks/driver/flower_photos'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["##### Load images into Dataframe"],"metadata":{}},{"cell_type":"markdown","source":["##### Using Spark's ImageSchema"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.image import ImageSchema\ndf = ImageSchema.readImages(img_dir)\ndf.show()\ndf.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n               image|\n+--------------------+\n[file:/databricks...|\n+--------------------+\n\nroot\n-- image: struct (nullable = true)\n    |-- origin: string (nullable = true)\n    |-- height: integer (nullable = false)\n    |-- width: integer (nullable = false)\n    |-- nChannels: integer (nullable = false)\n    |-- mode: integer (nullable = false)\n    |-- data: binary (nullable = false)\n\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["##### Using custom image library"],"metadata":{}},{"cell_type":"code","source":["from sparkdl.image import imageIO\nidf = imageIO.readImagesWithCustomFn(img_dir, decode_f=imageIO.PIL_decode)\nidf.show()\nidf.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+\nimage|\n+-----+\n null|\n+-----+\n\nroot\n-- image: struct (nullable = true)\n    |-- origin: string (nullable = true)\n    |-- height: integer (nullable = false)\n    |-- width: integer (nullable = false)\n    |-- nChannels: integer (nullable = false)\n    |-- mode: integer (nullable = false)\n    |-- data: binary (nullable = false)\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["##### Create the custom classifier"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\nfrom sparkdl import DeepImageFeaturizer"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["featurizer = DeepImageFeaturizer(inputCol='image', outputCol='features',modelName='ResNet50')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["lr = LogisticRegression(maxIter=10, regParam=0.05, elasticNetParam=0.3, labelCol='label')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["flo = Pipeline(stages=[featurizer, lr])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["##### Create the train and test class"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.image import ImageSchema\nfrom pyspark.sql.functions import lit\nfrom sparkdl.image import imageIO"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["tulips_df = ImageSchema.readImages(img_dir + '/tulips').withColumn('label',lit(0))\nsun_df = imageIO.readImagesWithCustomFn(img_dir + '/sunflowers',decode_f=imageIO.PIL_decode).withColumn('label',lit(1))\ntulips_train, tulips_test, _ = tulips_df.randomSplit([0.08, 0.08, 0.84])\nsun_train, sun_test, _ = sun_df.randomSplit([0.08, 0.08, 0.84])\ntrain_df = tulips_train.unionAll(sun_train)\ntest_df = tulips_test.unionAll(sun_test)\ntrain_df = train_df.repartition(100)\ntest_df = test_df.repartition(100)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["##### Train the model"],"metadata":{}},{"cell_type":"code","source":["f_model = flo.fit(train_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["##### Test the accuracy"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["tested_df = f_model.transform(test_df)\nevaluator = MulticlassClassificationEvaluator(metricName='accuracy')\nprint('Test set accuracy : ' + str(evaluator.evaluate(tested_df.select('prediction','label'))))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test set accuracy : 0.9016393442622951\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["##### Using a test image"],"metadata":{}},{"cell_type":"code","source":["    "],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":37}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.7","nbconvert_exporter":"python","file_extension":".py"},"name":"Deep Learning Pipelines on Databricks - 1.0.0","notebookId":281359362626780},"nbformat":4,"nbformat_minor":0}
