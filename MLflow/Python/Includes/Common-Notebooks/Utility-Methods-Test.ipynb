{"cells":[{"cell_type":"code","source":["\nspark.conf.set(\"com.databricks.training.module-name\", \"common-notebooks\")\n\ncourseAdvertisements = dict()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9926992b-c869-43f6-ad2f-afc25ef3d7a8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run ./Utility-Methods"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26ec6f58-e12f-434d-977c-7ae17eb46429"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pythonTests = []\ndef functionPassed(result):\n  if result:\n    pythonTests.append(True)\n  else:\n    pythonTests.append(False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db2f609b-e83b-4985-8b90-581cdd9bdb98"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `printRecordsPerPartition`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d483bfb-2c9b-4724-844c-7655d006f7a4"}}},{"cell_type":"code","source":["def testPrintRecordsPerPartition():\n  \n    # Import data\n    peopleDF = spark.read.parquet(\"/mnt/training/dataframes/people-10m.parquet\")\n    \n    # Get printed results\n    import io\n    from contextlib import redirect_stdout\n\n    f = io.StringIO()\n    with redirect_stdout(f):\n        printRecordsPerPartition(peopleDF)\n    out = f.getvalue()\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct number of partitions are printing\n    testsPassed.append(None)\n    try:\n        assert int(out[out.rfind('#') + 1]) == peopleDF.rdd.getNumPartitions()\n        passedTest(True)\n    except:\n        passedTest(False, \"The correct number of partitions were not identified for printRecordsPerPartition\")\n        \n    # Test if each printed partition has a record number associated\n    testsPassed.append(None)\n    try:\n        output_list = [\n          {val.split(\" \")[0].replace(\"#\", \"\").replace(\":\", \"\"): int(val.split(\" \")[1].replace(\",\", \"\"))} \n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ]\n        assert all([isinstance(x[list(x.keys())[0]], int) for x in output_list])\n        passedTest(True)\n    except:\n        passedTest(False, \"Not every partition has an associated record count\")\n        \n    # Test if the sum of the printed number of records per partition equals the total number of records\n    testsPassed.append(None)\n    try:\n        printedSum = sum([\n          int(val.split(\" \")[1].replace(\",\", \"\"))\n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ])\n      \n        assert printedSum == peopleDF.count()\n        passedTest(True)\n    except:\n        passedTest(False, \"The sum of the number of records per partition does not match the total number of records\")\n    \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for printRecordsPerPartition passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for printRecordsPerPartition passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testPrintRecordsPerPartition()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d4f0b1b-0564-4feb-b562-7935b3b31c0c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `computeFileStats`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"020bcff1-882b-42a2-ba00-999ecead89de"}}},{"cell_type":"code","source":["def testComputeFileStats():\n  \n    # Set file path\n    filePath = \"/mnt/training/global-sales/transactions/2017.parquet\"\n  \n    # Run and get output\n    output = computeFileStats(filePath)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 2\n        assert isinstance(output[0], int)\n        assert isinstance(output[1], int)\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect structure is returned for computeFileStats\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0] == 6276\n        assert output[1] == 1269333224\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect result is returned for computeFileStats\")\n        \n    # Test that nonexistent file path throws error\n    testsPassed.append(None)\n    try:\n        computeFileStats(\"alkshdahdnoinscoinwincwinecw/cw/cw/cd/c/wcdwdfobnwef\")\n        passedTest(False, \"A nonexistent file path did not throw an error for computeFileStats\")\n    except:\n        passedTest(True)\n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for computeFileStats passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for computeFileStats passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testComputeFileStats()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bda64bfd-935a-4618-ae0c-cfdcff53bb00"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `cacheAs`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"950e8e48-b081-4333-89d5-a626f7cd7ef7"}}},{"cell_type":"code","source":["def testCacheAs():\n  \n    # Import DF\n    inputDF = spark.read.parquet(\"/mnt/training/global-sales/transactions/2017.parquet\").limit(100)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test uncached table gets cached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Uncached table was not cached for cacheAs\")\n        \n    # Test cached table gets recached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Cached table was not recached for cacheAs\")\n        \n    # Test wrong level still gets cached\n    testsPassed.append(None)\n    try:\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        cacheAs(inputDF, \"testCacheTable12344321\", \"WRONG_LEVEL\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Invalid storage level stopping caching for cacheAs\")\n        \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for cacheAs passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for cacheAs passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testCacheAs()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a516b9ee-4479-411a-b2b9-ffd01e4ffd95"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `benchmarkCount()`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"132d48d0-64de-467e-b1d6-3bd520dff907"}}},{"cell_type":"code","source":["def testBenchmarkCount():\n  \n    from pyspark.sql import DataFrame\n    def testFunction():\n      return spark.createDataFrame([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n    output = benchmarkCount(testFunction)\n \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test that correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 3\n        assert isinstance(output[0], DataFrame)\n        assert isinstance(output[1], int)\n        assert isinstance(output[2], float)\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0].rdd.collect() == testFunction().rdd.collect()\n        assert output[1] == testFunction().count()\n        assert output[2] > 0 and output[2] < 10000\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")    \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for benchmarkCount passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for benchmarkCount passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testBenchmarkCount()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c21aa95-ad2a-4fa1-91d7-a137b2252cb4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test **`untilStreamIsReady()`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8258fbf7-d9fa-4e36-a0a3-c884d9044dd5"}}},{"cell_type":"code","source":["dataPath = \"dbfs:/mnt/training/definitive-guide/data/activity-data-stream.json\"\ndataSchema = \"Recorded_At timestamp, Device string, Index long, Model string, User string, _corrupt_record String, gt string, x double, y double, z double\"\n\ninitialDF = (spark\n  .readStream                            # Returns DataStreamReader\n  .option(\"maxFilesPerTrigger\", 1)       # Force processing of only 1 file per trigger \n  .schema(dataSchema)                    # Required for all streaming DataFrames\n  .json(dataPath)                        # The stream's source directory and file type\n)\n\nname = \"Testing_123\"\n\ndisplay(initialDF, streamName = name)\nuntilStreamIsReady(name)\nassert len(spark.streams.active) == 1, \"Expected 1 active stream, found \" + str(len(spark.streams.active))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aec560a1-b76c-4279-a0db-dad3fd65c8c5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for stream in spark.streams.active:\n  stream.stop()\n  queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  while (len(queries) > 0):\n    time.sleep(5) # Give it a couple of seconds\n    queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  print(\"\"\"The stream \"{}\" has been terminated.\"\"\".format(stream.name))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51ecd3e3-4309-4881-8365-6c66cf2eda2b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if all(pythonTests):\n    print('All {} tests for Python passed'.format(len(pythonTests)))\nelse:\n    print('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n    raise Exception('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cbaf65a2-9a64-4e27-98c2-d952e80c15d4"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Utility-Methods-Test","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2854191802663361}},"nbformat":4,"nbformat_minor":0}
