{"cells":[{"cell_type":"code","source":["\nspark.conf.set(\"com.databricks.training.module-name\", \"common-notebooks\")\n\ncourseAdvertisements = dict()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a22d87e6-9971-4de0-8055-df901a3539c9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run ./Utility-Methods"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3a50d07-6185-4b5c-805c-26b0421b93e4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pythonTests = []\ndef functionPassed(result):\n  if result:\n    pythonTests.append(True)\n  else:\n    pythonTests.append(False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78b59afd-b971-4812-88e1-2980cc45296a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `printRecordsPerPartition`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81c80272-ab43-458c-82d2-d2773ac7eb7b"}}},{"cell_type":"code","source":["def testPrintRecordsPerPartition():\n  \n    # Import data\n    peopleDF = spark.read.parquet(\"/mnt/training/dataframes/people-10m.parquet\")\n    \n    # Get printed results\n    import io\n    from contextlib import redirect_stdout\n\n    f = io.StringIO()\n    with redirect_stdout(f):\n        printRecordsPerPartition(peopleDF)\n    out = f.getvalue()\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct number of partitions are printing\n    testsPassed.append(None)\n    try:\n        assert int(out[out.rfind('#') + 1]) == peopleDF.rdd.getNumPartitions()\n        passedTest(True)\n    except:\n        passedTest(False, \"The correct number of partitions were not identified for printRecordsPerPartition\")\n        \n    # Test if each printed partition has a record number associated\n    testsPassed.append(None)\n    try:\n        output_list = [\n          {val.split(\" \")[0].replace(\"#\", \"\").replace(\":\", \"\"): int(val.split(\" \")[1].replace(\",\", \"\"))} \n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ]\n        assert all([isinstance(x[list(x.keys())[0]], int) for x in output_list])\n        passedTest(True)\n    except:\n        passedTest(False, \"Not every partition has an associated record count\")\n        \n    # Test if the sum of the printed number of records per partition equals the total number of records\n    testsPassed.append(None)\n    try:\n        printedSum = sum([\n          int(val.split(\" \")[1].replace(\",\", \"\"))\n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ])\n      \n        assert printedSum == peopleDF.count()\n        passedTest(True)\n    except:\n        passedTest(False, \"The sum of the number of records per partition does not match the total number of records\")\n    \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for printRecordsPerPartition passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for printRecordsPerPartition passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testPrintRecordsPerPartition()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29f3a6e7-c082-42e4-89a5-092d8e922e39"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `computeFileStats`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12e9c339-b39a-4d19-9ec6-7ad11d37e0a0"}}},{"cell_type":"code","source":["def testComputeFileStats():\n  \n    # Set file path\n    filePath = \"/mnt/training/global-sales/transactions/2017.parquet\"\n  \n    # Run and get output\n    output = computeFileStats(filePath)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 2\n        assert isinstance(output[0], int)\n        assert isinstance(output[1], int)\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect structure is returned for computeFileStats\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0] == 6276\n        assert output[1] == 1269333224\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect result is returned for computeFileStats\")\n        \n    # Test that nonexistent file path throws error\n    testsPassed.append(None)\n    try:\n        computeFileStats(\"alkshdahdnoinscoinwincwinecw/cw/cw/cd/c/wcdwdfobnwef\")\n        passedTest(False, \"A nonexistent file path did not throw an error for computeFileStats\")\n    except:\n        passedTest(True)\n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for computeFileStats passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for computeFileStats passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testComputeFileStats()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"037a3052-3fda-4951-a911-562438e0c6fd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `cacheAs`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45af0280-0d5f-4226-b46b-b149ad9c480a"}}},{"cell_type":"code","source":["def testCacheAs():\n  \n    # Import DF\n    inputDF = spark.read.parquet(\"/mnt/training/global-sales/transactions/2017.parquet\").limit(100)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test uncached table gets cached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Uncached table was not cached for cacheAs\")\n        \n    # Test cached table gets recached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Cached table was not recached for cacheAs\")\n        \n    # Test wrong level still gets cached\n    testsPassed.append(None)\n    try:\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        cacheAs(inputDF, \"testCacheTable12344321\", \"WRONG_LEVEL\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Invalid storage level stopping caching for cacheAs\")\n        \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for cacheAs passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for cacheAs passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testCacheAs()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f40a956-56cb-434b-822e-445db0ca3bb3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `benchmarkCount()`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1a36439-13e7-4fc8-a56a-a18183043a26"}}},{"cell_type":"code","source":["def testBenchmarkCount():\n  \n    from pyspark.sql import DataFrame\n    def testFunction():\n      return spark.createDataFrame([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n    output = benchmarkCount(testFunction)\n \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test that correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 3\n        assert isinstance(output[0], DataFrame)\n        assert isinstance(output[1], int)\n        assert isinstance(output[2], float)\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0].rdd.collect() == testFunction().rdd.collect()\n        assert output[1] == testFunction().count()\n        assert output[2] > 0 and output[2] < 10000\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")    \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for benchmarkCount passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for benchmarkCount passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testBenchmarkCount()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2aeebcaf-a8c2-4fe6-ae84-7877aa6ddb34"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test **`untilStreamIsReady()`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55878f7f-2fae-4a38-8050-99407cb46b9b"}}},{"cell_type":"code","source":["dataPath = \"dbfs:/mnt/training/definitive-guide/data/activity-data-stream.json\"\ndataSchema = \"Recorded_At timestamp, Device string, Index long, Model string, User string, _corrupt_record String, gt string, x double, y double, z double\"\n\ninitialDF = (spark\n  .readStream                            # Returns DataStreamReader\n  .option(\"maxFilesPerTrigger\", 1)       # Force processing of only 1 file per trigger \n  .schema(dataSchema)                    # Required for all streaming DataFrames\n  .json(dataPath)                        # The stream's source directory and file type\n)\n\nname = \"Testing_123\"\n\ndisplay(initialDF, streamName = name)\nuntilStreamIsReady(name)\nassert len(spark.streams.active) == 1, \"Expected 1 active stream, found \" + str(len(spark.streams.active))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a34ee93-7c43-4309-b4f7-f784b39b134c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for stream in spark.streams.active:\n  stream.stop()\n  queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  while (len(queries) > 0):\n    time.sleep(5) # Give it a couple of seconds\n    queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  print(\"\"\"The stream \"{}\" has been terminated.\"\"\".format(stream.name))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3e21ecc-8d6a-4e85-9160-52d14966629b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if all(pythonTests):\n    print('All {} tests for Python passed'.format(len(pythonTests)))\nelse:\n    print('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n    raise Exception('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1edf9a85-92b6-48d3-8155-3567f39c981b"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Utility-Methods-Test","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2854191802662599}},"nbformat":4,"nbformat_minor":0}
