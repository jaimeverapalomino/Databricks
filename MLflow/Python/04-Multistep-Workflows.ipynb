{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04dc793c-bd5b-493a-9f81-4f0ef623dc47"}}},{"cell_type":"markdown","source":["-sandbox\n# Multistep Workflows\n\nMachine learning projects quickly become complex when additional steps to the training process are added.  This lesson examines managing the complexity of multistep machine learning projects using multistep workflows.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Introduce multistep workflows\n - Execute a single, parameterized notebook as a step in a pipeline\n - Execute a multistep workflow\n\n## Prerequisites\n- Web browser: Chrome\n- A cluster configured with **8 cores** and **DBR 7.0 ML**\n \n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> This lesson makes use of the **`notebooks`** API which is currently unavailable on the Community Edition of Databricks."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fd89134-be83-4f9f-b4ca-56d741f82883"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the<br/>\nstart of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24c6d875-5b40-44d4-b650-e22e70269881"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34ea95d2-ec9c-4d9c-8105-d3702cd71415"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Managing the Complexity\n\nThe concept of pipelines...<br><br>\n\n - Available in Scikit-Learn and Spark ML\n - Bundle multiple stages of a pipeline together in a single object\n - Works well as first step in handling complexity\n \nBut they're limited...<br><br>\n\n - Don't scale to support arbitrary code\n - Work only with built-in functions\n - Do not allow for monitoring of each stage in the process\n\n**Multistep pipelines scales MLflow projects by allowing each stage to be its own project.**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b0e70a4-16c7-46d3-9cb2-4276c3f5d264"}}},{"cell_type":"markdown","source":["Multistep workflows...<br><br>\n\n - Allow for more robust pipelining with more complex stages\n - Use a flexible API\n - Work well for team collaboration: different people work on different stages\n\nThey work because **MLflow runs can recursively call other runs**  \n\nThis means that steps in a machine learning pipeline can be isolated."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4125be3e-cf74-483e-b927-48a575a03c43"}}},{"cell_type":"markdown","source":["-sandbox\nSome details...<br><br>\n\n - There are a few options for passing artifacts between runs\n - They can be saved to a common location or they can be logged as an artifact within MLflow\n - This also allows for quicker iteration since runs can be run individually\n - You only need to rerun a given step if the last step's results have been cached\n\nBelow is an example of a multistep workflow with four distinct steps.  <a href=\"https://github.com/mlflow/mlflow/tree/master/examples/multistep_workflow\" target=\"_blank\">You can see the full repository here.</a>\n\n<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlproject-architecture0.png\" style=\"height: 250px; margin: 20px\"/></div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"449e7f29-7a8d-45a2-889c-f47cae2297e2"}}},{"cell_type":"markdown","source":["-sandbox\n### Multistep Architecture\n\nNow that we can package projects and run them in their environment, let's look at how  we can make workflows consisting of multiple steps.    There are three general architectures to consider:<br><br>\n\n1. One driver project calls other entry points in that same project\n2. One driver project calls other projects \n3. One project calls another project as its final step\n\n<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlproject-architecture1.png\" style=\"height: 250px; margin: 20px\"/></div>\n<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlproject-architecture2.png\" style=\"height: 250px; margin: 20px\"/></div>\n<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlproject-architecture3.png\" style=\"height: 250px; margin: 20px\"/></div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18a05564-0004-4f6d-93b4-65b82122fd88"}}},{"cell_type":"markdown","source":["In the last lesson, we used a Python file as a project that we ran.  In this lesson, we'll use Databricks notebooks instead.  These are all under the `Multistep` folder in your directory of notebooks.  There are two things to note about notebooks:<br><br>\n\n0. Notebooks can be run using `dbutils.notebook.run(\"<path>\", \"<timeout>\")`\n0. Notebooks can be parameterized using widgets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86c9c3a2-e0c7-4166-83f7-f086bcb78af8"}}},{"cell_type":"markdown","source":["Run the following code to see how this works."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad1bd951-98d9-4020-8dac-0fc900bfbcfe"}}},{"cell_type":"code","source":["step1 = dbutils.notebook.run(\"./Multistep/Step-1-Read-Data\", 60, \n  {\"data_input_path\": \"/dbfs/mnt/training/airbnb/sf-listings/airbnb-cleaned-mlflow.csv\"})\n\nprint(step1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"502eccba-4fe2-4515-a7b1-d0fcb8bbfbf4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["This is the first step of our multistep workflow.  From the above, you can see that we ran the notebook `Step-1-Read-Data` in the `Multistep` directory.  We had a timeout of 60 seconds so if the code doesn't complete in that time, it would have failed.  Finally, we have the input path for our data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96aca5cf-64c0-48ef-9bed-392b4fc6126f"}}},{"cell_type":"markdown","source":["[Take a look at the underlying notebook.]($./Multistep/Step-1-Read-Data)  Note the following is accomplished in four cells:<br><br>\n\n0. Widgets are declared.  If you run these cells in the notebook itself, you'll see widgets appear at the top of the screen.  Widgets allow for the customization of notebooks without editing the code itself. They also allow for passing parameters into notebooks. \n0. Widgets are read.  This allows you to get the value of the widget and use it in your code.\n0. An MLflow run logs the data from `data_input_path` as an artifact\n0. The notebook exits and reports back information to the parent notebook (in our case, that's this notebook)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"029c2daf-4c4c-4f88-a4ef-071354ca5b77"}}},{"cell_type":"markdown","source":["-sandbox\nWe can get data back from the executed notebook by parsing the exit string.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> For debugging, you can either write your code in a notebook and then execute it as a run or you can click on `Notebook job #XXX` that appears after using `dbutils.notebook.run` to see where any problems might be."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ccb9b3b8-52eb-480c-9773-3271f1200b33"}}},{"cell_type":"code","source":["import json\n\ndata_output_path = json.loads(step1).get(\"data_output_path\")\n\nprint(data_output_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd91e9aa-a1bd-480c-8be2-e1649c3711b8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Multistep Workflow\n\nNow that we've created a single executable notebook with input parameters and output data, we can create more complex workflows.  [Take a look at the second step in our workflow.]($./Multistep/Step-2-Train)  This notebook takes the data logged as an artifact and trains a model using specific hyperparameters.  The trained model is also logged."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd5487be-be4f-4344-b9d0-213e131dcdf2"}}},{"cell_type":"code","source":["step2 = dbutils.notebook.run(\"./Multistep/Step-2-Train\", 60, \n  {\"artifact_URI\": data_output_path,\n   \"n_estimators\": 10,\n   \"max_depth\": 20,\n   \"max_features\": \"auto\"})\n\nprint(step2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc8ed19c-637b-4a22-9e82-cc6fb4e2c4eb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Get the model output path from the result."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e447dc1f-817c-4cb8-9268-3bf5c777ff84"}}},{"cell_type":"code","source":["model_output_path = json.loads(step2).get(\"model_output_path\")\n\nprint(model_output_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"365a7d9f-dc8b-4c52-ab0f-ea3102f0f516"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now [take a look at the final step in our workflow.]($./Multistep/Step-3-Predict)  This step takes the saved model and creates predictions from it.  It logs those predictions as an artifact."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f419bc8-6456-4550-b4a9-8ebd23d05cda"}}},{"cell_type":"code","source":["step3 = dbutils.notebook.run(\"./Multistep/Step-3-Predict\", 60, \n  {\"model_path\": model_output_path,\n   \"data_path\": data_output_path})\n\nprint(step3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ddc1d56-7cf3-48fb-9634-24c96285dc41"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Parse the notebook output to see the predictions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39f1bbb1-286b-42b2-8021-70d137f8bcdd"}}},{"cell_type":"code","source":["predictions_output_path = json.loads(step3).get(\"predictions_output_path\")\n\nprint(dbutils.fs.head(dbutils.fs.ls(predictions_output_path)[0].path))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ac1b026-4863-444e-9a2d-5661f9cd70d0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Review\n\n**Question:** What are the benefits of pipelining?  \n**Answer:** The biggest benefit to pipelining is managing the complexity of the machine learning process.  With loading, ETL, featurization, training, and prediction stages--to name a few--the complexity of the process quickly grows.  One additional benefit is collaboration since different individuals can work on different stages in the pipeline.\n\n**Question:** How can I manage a pipeline using MLflow?  \n**Answer:** Multi-step workflows chain together multiple MLflow jobs.  Runs can recursively call other runs.  This allows each stage to be its own MLflow project with its own environment, inputs, and outputs."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"265224db-13ed-4e8b-ad33-3d9f552b120c"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d9c60de4-3b28-412a-8b0e-761dbf148fb3"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Cleanup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86334e1c-6dc0-42db-9490-6a662476618c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Next Steps\n\nStart the labs for this lesson, [Multistep Workflows Lab]($./Labs/04-Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2a11ec1-685c-4d17-9901-03560324f89f"}}},{"cell_type":"markdown","source":["## Additional Topics & Resources\n\n**Q:** Where can I find out more information on the future of Multistep Workflows?  \n**A:** Check out Aaron Davidson's demo <a href=\"https://databricks.com/session/accelerating-the-machine-learning-lifecycle-with-mlflow-1-0\" target=\"_blank\">at Spark Summit 2019 for the direction of the project.</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"536a26ad-c041-4ed1-a13b-fef0db8c26b5"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"199bf979-4d29-41a3-853a-538045d3a59e"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"04-Multistep-Workflows","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2854191802662884}},"nbformat":4,"nbformat_minor":0}
