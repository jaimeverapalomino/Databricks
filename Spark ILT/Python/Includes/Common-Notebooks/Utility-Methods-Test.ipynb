{"cells":[{"cell_type":"code","source":["\nspark.conf.set(\"com.databricks.training.module-name\", \"common-notebooks\")\n\ncourseAdvertisements = dict()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"227292ba-c961-4ee7-9fac-dc239b33973e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run ./Utility-Methods"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d88c7715-6a51-4891-b89f-51cc7b583ed2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pythonTests = []\ndef functionPassed(result):\n  if result:\n    pythonTests.append(True)\n  else:\n    pythonTests.append(False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b55f7af-cd1f-4487-9737-ca3694dff442"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `printRecordsPerPartition`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70553693-933e-4d26-ab83-6eaba7cec6be"}}},{"cell_type":"code","source":["def testPrintRecordsPerPartition():\n  \n    # Import data\n    peopleDF = spark.read.parquet(\"/mnt/training/dataframes/people-10m.parquet\")\n    \n    # Get printed results\n    import io\n    from contextlib import redirect_stdout\n\n    f = io.StringIO()\n    with redirect_stdout(f):\n        printRecordsPerPartition(peopleDF)\n    out = f.getvalue()\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct number of partitions are printing\n    testsPassed.append(None)\n    try:\n        assert int(out[out.rfind('#') + 1]) == peopleDF.rdd.getNumPartitions()\n        passedTest(True)\n    except:\n        passedTest(False, \"The correct number of partitions were not identified for printRecordsPerPartition\")\n        \n    # Test if each printed partition has a record number associated\n    testsPassed.append(None)\n    try:\n        output_list = [\n          {val.split(\" \")[0].replace(\"#\", \"\").replace(\":\", \"\"): int(val.split(\" \")[1].replace(\",\", \"\"))} \n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ]\n        assert all([isinstance(x[list(x.keys())[0]], int) for x in output_list])\n        passedTest(True)\n    except:\n        passedTest(False, \"Not every partition has an associated record count\")\n        \n    # Test if the sum of the printed number of records per partition equals the total number of records\n    testsPassed.append(None)\n    try:\n        printedSum = sum([\n          int(val.split(\" \")[1].replace(\",\", \"\"))\n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ])\n      \n        assert printedSum == peopleDF.count()\n        passedTest(True)\n    except:\n        passedTest(False, \"The sum of the number of records per partition does not match the total number of records\")\n    \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for printRecordsPerPartition passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for printRecordsPerPartition passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testPrintRecordsPerPartition()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e6f0d40-9444-45c4-870d-767c01cb8003"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `computeFileStats`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12c9ca40-7843-4ab3-9cc1-0a2da7b34572"}}},{"cell_type":"code","source":["def testComputeFileStats():\n  \n    # Set file path\n    filePath = \"/mnt/training/global-sales/transactions/2017.parquet\"\n  \n    # Run and get output\n    output = computeFileStats(filePath)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 2\n        assert isinstance(output[0], int)\n        assert isinstance(output[1], int)\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect structure is returned for computeFileStats\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0] == 6276\n        assert output[1] == 1269333224\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect result is returned for computeFileStats\")\n        \n    # Test that nonexistent file path throws error\n    testsPassed.append(None)\n    try:\n        computeFileStats(\"alkshdahdnoinscoinwincwinecw/cw/cw/cd/c/wcdwdfobnwef\")\n        passedTest(False, \"A nonexistent file path did not throw an error for computeFileStats\")\n    except:\n        passedTest(True)\n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for computeFileStats passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for computeFileStats passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testComputeFileStats()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95c1ddcb-6350-4122-b261-a0dc3e5efc77"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `cacheAs`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12b00d4a-db6e-4ff2-9a13-483ef763b8ca"}}},{"cell_type":"code","source":["def testCacheAs():\n  \n    # Import DF\n    inputDF = spark.read.parquet(\"/mnt/training/global-sales/transactions/2017.parquet\").limit(100)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test uncached table gets cached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Uncached table was not cached for cacheAs\")\n        \n    # Test cached table gets recached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Cached table was not recached for cacheAs\")\n        \n    # Test wrong level still gets cached\n    testsPassed.append(None)\n    try:\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        cacheAs(inputDF, \"testCacheTable12344321\", \"WRONG_LEVEL\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Invalid storage level stopping caching for cacheAs\")\n        \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for cacheAs passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for cacheAs passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testCacheAs()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d1dc98f-7a61-4b2d-8257-dff393d8bf23"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `benchmarkCount()`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3e0f00e-3214-41e3-b324-2510ebb31c59"}}},{"cell_type":"code","source":["def testBenchmarkCount():\n  \n    from pyspark.sql import DataFrame\n    def testFunction():\n      return spark.createDataFrame([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n    output = benchmarkCount(testFunction)\n \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test that correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 3\n        assert isinstance(output[0], DataFrame)\n        assert isinstance(output[1], int)\n        assert isinstance(output[2], float)\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0].rdd.collect() == testFunction().rdd.collect()\n        assert output[1] == testFunction().count()\n        assert output[2] > 0 and output[2] < 10000\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")    \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for benchmarkCount passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for benchmarkCount passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testBenchmarkCount()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5851c11f-3993-47a4-9476-5e1fc547a07e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test **`untilStreamIsReady()`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"932a489e-e945-489b-90c0-6ad09dfa86ff"}}},{"cell_type":"code","source":["dataPath = \"dbfs:/mnt/training/definitive-guide/data/activity-data-stream.json\"\ndataSchema = \"Recorded_At timestamp, Device string, Index long, Model string, User string, _corrupt_record String, gt string, x double, y double, z double\"\n\ninitialDF = (spark\n  .readStream                            # Returns DataStreamReader\n  .option(\"maxFilesPerTrigger\", 1)       # Force processing of only 1 file per trigger \n  .schema(dataSchema)                    # Required for all streaming DataFrames\n  .json(dataPath)                        # The stream's source directory and file type\n)\n\nname = \"Testing_123\"\n\ndisplay(initialDF, streamName = name)\nuntilStreamIsReady(name)\nassert len(spark.streams.active) == 1, \"Expected 1 active stream, found \" + str(len(spark.streams.active))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"675e1e49-7c26-4191-a0e0-3df9d99877ec"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for stream in spark.streams.active:\n  stream.stop()\n  queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  while (len(queries) > 0):\n    time.sleep(5) # Give it a couple of seconds\n    queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  print(\"\"\"The stream \"{}\" has been terminated.\"\"\".format(stream.name))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad62bd5a-3fb3-4269-a6f8-65b038d02bb9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if all(pythonTests):\n    print('All {} tests for Python passed'.format(len(pythonTests)))\nelse:\n    print('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n    raise Exception('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b397027-523c-40f5-a9cc-ad596e2881ce"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Utility-Methods-Test","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840793}},"nbformat":4,"nbformat_minor":0}
