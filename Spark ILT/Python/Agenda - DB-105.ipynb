{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70cd74d8-424e-4531-b48c-f97ff6bba845"}}},{"cell_type":"markdown","source":["# Course Agenda\n## DB 105 - Apache Sparkâ„¢ Programming (3-Day)\n### Day-1 AM\n\n<table>\n<tr><td>50 m</td><td>Introductions</td><td><i>Student and instructor introductions, roll call, etc</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>20 m</td><td>Setup</td><td><i>Courseware Install & Setup</i></td></tr>\n<tr><td>30 m</td><td>[Apache Spark Overview]($./Apache Spark Overview)</td><td><i>About Databricks, Apache Spark & Spark's Architecture</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>20 m</td><td>[The Databricks Environment]($./Other Topics/Databricks Environment)</td><td><i>DBFS, dbutils, Magic Commands: %run, %sh, %md, %fs</i></td></tr>\n<tr><td>30 m</td><td>[Reading Data - CSV]($./Reading & Writing Data/DFRW 1 - CSV)</td><td><i>Spark Entry Point, Reading Data, Inferring Schemas, API Docs</i></td></tr>\n<tr><td>10 m</td><td>[Reading Data - Parquet]($./Reading & Writing Data/DFRW 2 - Parquet)</td><td><i>The #1 recommended format for storing big data</i></td></tr>\n</table>\n\n### Day-1 PM\n\n<table>\n<tr><td>20 m</td><td>Reading Data - More Examples</td><td><i>We will introduce as many as time permits</i></td></tr>\n<tr><td></td><td>[Reading Data - Tables]($./Reading & Writing Data/DFRW 3 - Tables)</td><td><i>See how Databricks makes registering datasets easy with the Tables UI</i></td></tr>\n<tr><td></td><td>[Reading Data - JSON]($./Reading & Writing Data/DFRW 4 - JSON)</td><td><i>Complex Data Types, JSON-Lines, Multi-line JSON</i></td></tr>\n<tr><td></td><td>[Reading Data - Text]($./Reading & Writing Data/DFRW 5 - Text)</td><td><i>Simple Text files</i></td></tr>\n<tr><td></td><td>[Reading Data - JDBC]($./Reading & Writing Data/DFRW 6 - JDBC)</td><td><i>Review and contrast the differences of various readers</i></td></tr>\n<tr><td></td><td>[Reading Data - Summary]($./Reading & Writing Data/DFRW 7 - Summary)</td><td><i>Review and contrast the differences of various readers</i></td></tr>\n  <tr><td>30 m</td><td>[Lab: Reading Data]($./Reading & Writing Data/DFRW 8 - Lab)</td><td><i>Putting to practice what we just learned (completed collaboratively)</i></td></tr>\n<tr><td></td><td>[Writing Data]($./Reading & Writing Data/DFRW 9 - Writing Data)</td><td><i>Short example of how to use DataFrame Writers</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>50 m</td><td>[Intro to Dataframes Part 1]($./Intro To DataFrames/Intro To DF Part 1)</td><td><i>DatFrames, cache(), show(), display(), limit(), select(), drop(), distinct() SQL, Temp Views</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>30 m</td><td>[Lab: Distinct Articles]($./Intro To DataFrames/Intro To DF Part 1 Lab)</td><td><i>Putting to practice what we just learned</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>50 m</td><td>[Transformations and Actions]($./Other Topics/Transformations And Actions)</td><td><i>Lazy, Catalyst, Actions, Transformations, Wide vs. Narrow, Shuffling, Stages, Pipelining, Lineage</i></td></tr>\n<tr><td>30 m</td><td>[Lab: T&A in the Spark UI]($./Other Topics/Transformations And Actions Lab)</td><td><i>Explore the effects of the Transformations and Actions while exploring the Spark UI</i></td></tr>\n</table>\n\n### Day-2 AM\n\n<table>\n<tr><td>30 m</td><td>Review</td><td><i>Review topics and lessons from the previous day</i></td></tr>\n<tr><td>20 m</td><td>[Caching]($./Other Topics/Caching)</td><td><i>cache(), persist(), unpersist(), RDD Name, don't cache!</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>50 m</td><td>[Intro to DataFrames Part 2]($./Intro To DataFrames/Intro To DF Part 2)</td><td><i>orderBy(), Column, filter(), first(), Row, collect(), take(n), DataFrame vs DataSet</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>30 m</td><td>[Lab: Washingtons and Marthas]($./Intro To DataFrames/Intro To DF Part 2 Lab)</td><td><i>Counting and summing Washingtons and Adams - how many different ways can you solve the same problem?</i></td></tr>\n<tr><td>30 m</td><td>[Catalyst Optimizer]($./Other Topics/Catalyst Optimizer)</td><td><i>Logical, Optimized, & Physical Plan, Cost Model, WholeStageCodegen, Predicate Pushdown</i></td></tr>\n</table>\n\n### Day-2 PM\n\n<table>\n<tr><td>50 m</td><td>Partitioning</td><td><i>Partitions vs. Slots, repartition(n), coalesce(n), spark.sql.shuffle.partitions</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>20 m</td><td>Lab: Exploring Partitions</td><td><i>Explore the real-word consequences of partition sizes</i></td></tr>\n<tr><td>60 m</td><td>[Intro to DataFrames Part 3]($./Intro To DataFrames/Intro To DF Part 3 Lab)</td><td><i>withCloumnRenamed(), withColumn(), unix_timestamp(), & cast()</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>60 m</td><td>[Lab: De-Duping Data]($./Intro To DataFrames/Intro To DF Part 3 Lab)</td><td><i>real world problem solving - removing duplicate records</i></td></tr>\n<tr><td>30 m</td><td>Q&A</td><td><i></i></td></tr>\n</table>\n\n### Day-3 AM\n\n<table>\n<tr><td>30 m</td><td>Review</td><td><i>Review topics and lessons from the previous day</i></td></tr>\n<tr><td>40 m</td><td>[Intro to DataFrames Part 4]($./Intro To DataFrames/Intro To DF Part 4)</td><td><i>date_format(), User Defined Functions, Mondays, join()</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>50 m</td><td>[Lab: What the Monday?]($./Intro To DataFrames/Intro To DF Part 4 Lab)</td><td><i>What is going on with Mondays?</i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>40 m</td><td>[Intro to DataFrames Part 5]($./Intro To DataFrames/Intro To DF Part 5)</td><td><i>Broadcast joins, broadcast()</i></td></tr>\n</table>\n\n### Day-3 PM\n\n<table>\n<tr><td>15 m</td><td>House Keeping</td><td><i></i></td></tr>\n<tr><td>45 m</td><td>Structured Streaming Hour 1</td><td><i></i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>50 m</td><td>Structured Streaming Hour 2</td><td><i></i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>50 m</td><td>Structured Streaming Hour 3</td><td><i></i></td></tr>\n<tr><td>10 m</td><td>Break</td><td><i></i></td></tr>\n<tr><td>20 m</td><td>Machine Learning Pipeline</td><td><i>ML Pipelines, Feature Extractors, Random Forests, Evaluators, Param Grids, Cross Validation</i></td></tr>\n<tr><td>30 m</td><td>Q&A & Specail Requests</td><td><i>Revisit other topics, special requests and last minute questions.</i></td></tr>\n</table>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42d82fcd-a879-48f8-bef3-21d5b7ddbb92"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37567362-efff-444b-9f20-d04186e880f5"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Agenda - DB-105","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840439}},"nbformat":4,"nbformat_minor":0}
