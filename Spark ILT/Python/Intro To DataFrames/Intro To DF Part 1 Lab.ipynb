{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a831bf7e-1948-492b-9e53-fc4b4305989a"}}},{"cell_type":"markdown","source":["# Introduction to DataFrames, Lab #1\n## Distinct Articles"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d973d17-b158-4399-a769-2ae8da19e386"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Instructions\n\nIn the cell provided below, write the code necessary to count the number of distinct articles in our data set.\n0. Copy and paste all you like from the previous notebook.\n0. Read in our parquet files.\n0. Apply the necessary transformations.\n0. Assign the count to the variable `totalArticles`\n0. Run the last cell to verify that the data was loaded correctly.\n\n**Bonus**\n\nIf you recall from the beginning of the previous notebook, the act of reading in our parquet files will trigger a job.\n0. Define a schema that matches the data we are working with.\n0. Update the read operation to use the schema."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bfd4139f-5b07-4899-8814-28decc233d60"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"905ff24c-de79-4661-9e9f-e9f04da0d530"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ac08b86-e506-43ee-95cd-5736a3121984"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Show Your Work"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01a1e33b-a739-4b08-be64-5721f82d909f"}}},{"cell_type":"code","source":["(source, sasEntity, sasToken) = getAzureDataSource()\nspark.conf.set(sasEntity, sasToken)\n\npath = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc813904-cc9d-4b05-8201-5ac7f4a55833"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# TODO\nReplace FILL_IN with your code. \n\ndf = (spark                # Our SparkSession & Entry Point\n  .read                    # Our DataFrameReader\n  FILL_IN                  # Read in the parquet files\n  FILL_IN                  # Reduce the columns to just the one\n  FILL_IN                  # Produce a unique set of values\n)\ntotalArticles = df.FILL_IN # Identify the total number of records remaining.\n\nprint(f\"Distinct Articles: {totalArticles:,}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33ccb05c-1a06-4886-93d4-ccb3cf62cd26"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30ac4c9d-2a46-4d81-acf3-394e1c8624de"}}},{"cell_type":"code","source":["expected = 1783138\nassert totalArticles == expected, \"Expected the total to be \" + str(expected) + \" but found \" + str(totalArticles)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f276f1c-d066-4193-95e3-52be9ff54503"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ace3d931-d04c-4b23-81c1-70a4454a8d03"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"812282a8-c5fd-4735-af66-d6be6981d2f0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0bdc4bc-2fb3-4941-94d8-990de33d4ebf"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Intro To DF Part 1 Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577839673}},"nbformat":4,"nbformat_minor":0}
