{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ebfcee5-d97d-40ed-a6d8-2df5997a465d"}}},{"cell_type":"markdown","source":["# The Databricks Environment\n\n**Technical Accomplishments:**\n- Set the stage for learning on the Databricks platform\n- Demonstrate how to develop & execute code within a notebook.\n- Introduce the Databricks File System (DBFS)\n- Introduce **`dbutils`**\n- Review the various \"Magic Commands\"\n- Review various built-in commands that facilitate working with the notebooks"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f907fd79-53cb-47f0-9d8a-00e7fdcab28c"}}},{"cell_type":"markdown","source":["-sandbox\n##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Scala, Python, R, SQL\n\n* Each notebook is tied to a specific language: **Scala**, **Python**, **SQL** or **R**\n* Run the cell below using one of the following options:\n  * **CTRL+ENTER** or **CMD+RETURN**\n  * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one\n  * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style=\"box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);\" src=\"https://files.training.databricks.com/images/notebook-cell-run-cmd.png\"/>\n\nFeel free to tweak the code below if you like:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ac5e8bc-e66f-4932-810e-5e4158f9372b"}}},{"cell_type":"code","source":["print(\"I'm running Python!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f9bbf7a-d3f6-4ce9-8a05-8aed37fb9b19"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Magic Commands\n* Magic Commands are specific to the Databricks notebooks\n* They are very similar to Magic Commands found in comparable notebook products\n* These are built-in commands that do not apply to the notebook's default language\n* A single percent (%) symbol at the start of a cell identifies a Magic Commands"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a564c51e-20be-4616-a56a-fbf01bd1d0e7"}}},{"cell_type":"markdown","source":["### Magic Command: &percnt;sh\nFor example, **&percnt;sh** allows us to execute shell commands on the driver"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad076479-6d7f-42fd-b215-70d1839aacf2"}}},{"cell_type":"code","source":["%sh ps | grep 'java'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08cb3794-7295-484b-a2e2-1e7142828187"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Magic Command: Other Languages\nAdditional Magic Commands allow for the execution of code in languages other than the notebook's default:\n* **&percnt;python** \n* **&percnt;scala** \n* **&percnt;sql** \n* **&percnt;r**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d5ba052-ee63-4a8c-a4b5-44723a9b9bba"}}},{"cell_type":"code","source":["%scala\n\nprintln(\"Hello Scala!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a421bc29-158b-4f3f-a3c6-a86a44975c43"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n\nprint(\"Hello Python!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5c55574-4954-40ad-9177-233086c03ae8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%r\n\nprint(\"Hello R!\", quote=FALSE)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96fa5128-137a-4f6c-b7d7-212cc1f91ef0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n\nselect \"Hello SQL!\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16e3c39e-18dc-49a5-a1eb-b637dd7b07ea"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Magic Command: &percnt;md\n\nOur favorite Magic Command **&percnt;md** allows us to render Markdown in a cell:\n* Double click this cell to begin editing it\n* Then hit `Esc` to stop editing\n\n# Title One\n## Title Two\n### Title Three\n\nThis is a test of the emergency broadcast system. This is only a test.\n\nThis is text with a **bold** word in it.\n\nThis is text with an *italicized* word in it.\n\nThis is an ordered list\n0. once\n0. two\n0. three\n\nThis is an unordered list\n* apples\n* peaches\n* bananas\n\nLinks/Embedded HTML: <a href=\"http://bfy.tw/19zq\" target=\"_blank\">What is Markdown?</a>\n\nImages:  \n![Spark Engines](https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png)\n\nAnd of course, tables:\n\n| Name  | Age | Sex    |\n|-------|-----|--------|\n| Tom   | 32  | Male   |\n| Mary  | 29  | Female |\n| Dick  | 73  | Male   |\n| Sally | 55  | Female |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd48803f-2dd2-4e98-bb15-e5b9a42a1188"}}},{"cell_type":"markdown","source":["### Magic Command: &percnt;run\n* You can run a notebook from another notebook by using the Magic Command **%run** \n* All variables & functions defined in that other notebook will become available in your current notebook\n\nFor example, The following cell should fail to execute because the variable `username` has not yet been declared:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36927290-27f1-4f87-bb6c-058e36bbf2e1"}}},{"cell_type":"code","source":["# Uncomment and try this:\n# print(\"username: \" + username)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92d37493-d181-4db3-a5e3-4f2d8de131d5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["But we can declare it and a handful of other variables and functions buy running this cell:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da918c26-6899-4367-ae01-59b171e37e37"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc37ba94-1aad-4394-9edd-4e3a7078e53f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["In this case, the notebook `Classroom-Setup` declares the following:\n  * The variable `username`\n  * The variable `userhome`\n  * The function `assertSparkVersion(..)`\n  * And others..."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9221cfc3-1689-4e0c-b96f-b4e35fee474a"}}},{"cell_type":"code","source":["print(\"username: \" + username)\nprint(\"userhome: \" + userhome)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"796fef31-6218-499f-87ee-2260b9f0e70e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We will use those variables and functions throughout this class.\n\nOne of the other things `Classroom-Setup` does for us is to mount all the datasets needed for this class into the Databricks File System."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"202566d9-8785-4eac-92d4-87b14595103c"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Databricks File System - DBFS\n* DBFS is a layer over a cloud-based object store\n* Files in DBFS are persisted to the object store\n* The lifetime of files in the DBFS are **NOT** tied to the lifetime of our cluster"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9367b7ab-ec74-41ca-8ec8-3c30efc5cb46"}}},{"cell_type":"markdown","source":["### Mounting Data into DBFS\n* Mounting other object stores into DBFS gives Databricks users access via the file system\n* This is just one of many techniques for pulling data into Spark\n* The datasets needed for this class have already been mounted for us with the call to `%run \"../Includes/Classroom-Setup\"`\n* We will confirm that in just a few minutes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"635b450d-9026-48f9-b3cf-d1e87a1006e1"}}},{"cell_type":"markdown","source":["See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbfs-databricks-file-system.html\" target=\"_blank\">Databricks File System - DBFS</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed962eb0-53c4-4852-ae20-1e68e9fd1832"}}},{"cell_type":"markdown","source":["### Databricks Utilities - dbutils\n* You can access the DBFS through the Databricks Utilities class (and other file IO routines).\n* An instance of DBUtils is already declared for us as `dbutils`.\n* For in-notebook documentation on DBUtils you can execute the command `dbutils.help()`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4eb7e40-894c-45ed-9b79-528c1f40f250"}}},{"cell_type":"markdown","source":["See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbutils.html\" target=\"_blank\">Databricks Utilities - dbutils</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe34ab3e-5bd9-438f-b86d-f0a2b825c79f"}}},{"cell_type":"code","source":["dbutils.help()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a2c5968-2ccc-4b3c-9eb6-25fa25007ee6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Additional help is available for each sub-utility:\n* `dbutils.fs.help()`\n* `dbutils.meta.help()`\n* `dbutils.notebook.help()`\n* `dbutils.widgets.help()`\n\nLet's take a look at the file system utilities, `dbutils.fs`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64ec1930-f97c-48e8-bb24-7837020d0e24"}}},{"cell_type":"code","source":["dbutils.fs.help()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d202319-3d1e-480f-a13a-ceef2eadc201"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### dbutils.fs.mounts()\n* As previously mentioned, all our datasets should already be mounted\n* We can use `dbutils.fs.mounts()` to verify that assertion\n* This method returns a collection of `MountInfo` objects, one for each mount"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee67edb3-c35c-4a5e-8e1d-488676fee231"}}},{"cell_type":"code","source":["mounts = dbutils.fs.mounts()\n\nfor mount in mounts:\n  print(mount.mountPoint + \" >> \" + mount.source) \n  \nprint(\"-\"*80)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e50a398e-f20c-4d1f-a848-72a2f8b3e1bb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### dbutils.fs.ls(..)\n* And now we can use `dbutils.fs.ls(..)` to view the contents of that mount\n* This method returns a collection of `FileInfo` objects, one for each item in the specified directory"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7b3bf0c-943e-46fe-a101-36ce9fe3167f"}}},{"cell_type":"markdown","source":["See also <a href=\"https://docs.azuredatabricks.net/api/latest/dbfs.html#dbfsfileinfo\" target=\"_blank\">FileInfo</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28bf3456-05cf-4e65-94b3-7d4143f3aaa3"}}},{"cell_type":"code","source":["files = dbutils.fs.ls(\"/mnt/training/\")\n\nfor fileInfo in files:\n  print(fileInfo.path)\n  \nprint(\"-\"*80)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2f86cae-e564-4280-b6d3-6f32aec218bf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### display(..)\n\nBesides printing each item returned from `dbutils.fs.ls(..)` we can also pass that collection to another Databricks specific command called `display(..)`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"793f2572-992f-4bb3-ac62-6cdcb03104eb"}}},{"cell_type":"code","source":["files = dbutils.fs.ls(\"/mnt/training/\")\n\ndisplay(files)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e32c2fdf-e645-4d29-a114-719cd0dbfee2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The `display(..)` command is overloaded with a lot of other capabilities:\n* Presents up to 1000 records.\n* Exporting data as CSV.\n* Rendering a multitude of different graphs.\n* Rendering geo-located data on a world map.\n\nAnd as we will see later, it is also an excellent tool for previewing our data in a notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2f04109-5217-4bcd-a152-bd8b7d782add"}}},{"cell_type":"markdown","source":["### Magic Command: &percnt;fs\n\nThere is at least one more trick for looking at the DBFS.\n\nIt is a wrapper around `dbutils.fs` and it is the Magic Command known as **&percnt;fs**.\n\nThe following call is equivalent to the previous call, `display( dbutils.fs.ls(\"/mnt/training\") )` - there is no real difference between the two."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab52cec9-dd0e-4bb1-8a46-8544c8fb0edc"}}},{"cell_type":"code","source":["%fs ls /mnt/training"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42efc579-76db-4802-b3b8-b2b453ebad81"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) displayHTML(..)\n\nOne more Databricks-specific command we may use later is `displayHTML(..)`\n\nThis command will render your custom HTML in an `IFRAME` and then present that in our notebook and/or dashboard.\n\nThe really nice thing about this is that you can make this call directly from your code making it really easy to customize the presentation of your data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3f9483b-1a51-49b4-b1b5-3c6753453c5c"}}},{"cell_type":"code","source":["choices = [\"red\", \"green\", \"blue\"]\n\nhtml = \"\"\"\n<body>\n  <h1>This is HTML</h1>\n  <div style=\"color:red\">What is your favorite color?</div>\n\"\"\"\n\nfor choice in choices:\n  html += \"\"\"<label for=\"{}\" style=\"margin:0\"><input id=\"{}\" type=\"radio\" name=\"answer\" style=\"vertical-align:top\"> {}</label><br/>\"\"\".format(choice, choice, choice)\n\nhtml += \"\"\"\n</body>\n\"\"\"\n\ndisplayHTML(html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c61c5c2-dd43-4da7-bd9a-da1d33d8811f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Widgets\n\nInput widgets allow you to add parameters to your notebooks and dashboards. The widget API consists of calls to create different types of input widgets, remove them, and get bound values.\n\nWidgets are best for:\n\n * Building a notebook or dashboard that is re-executed with different parameters\n * Quickly exploring results of a single query with different parameters\n\n\nView the documentation for the widget API in Scala, Python, and R with the following command:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6b94d9d-d5b8-41d2-b3d3-01bcbfeccda2"}}},{"cell_type":"code","source":["dbutils.widgets.help()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fcd3b99-8dbc-4a5c-8c99-0d6669df92f1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Execute the following cell to create two widgets on the top of the screen."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba810355-64a1-449c-a017-fff7336ac18c"}}},{"cell_type":"code","source":["dbutils.widgets.combobox(\"hihey\",\"Hi\", [\"Hi\", \"Hey\", \"Hello\"], \"Oh,\")\ndbutils.widgets.text(\"name\", \"Anonymous\", \"Your name\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da72d8fb-06e1-4d95-bedd-fa6159f58240"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Change the values of the widgets and watch the result of the next cell change:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1130d5db-868b-4a82-8347-14b3aed7d27e"}}},{"cell_type":"code","source":["displayHTML(\"<h2>\" + dbutils.widgets.get(\"hihey\") + \" \" + dbutils.widgets.get(\"name\") + \", Welcome to Databricks!</h2>\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e3aa297-660e-4040-9bb9-e824d9c8aecb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now remove all the widgets:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39e2d901-d8d7-444a-82fb-e040b5bd3a29"}}},{"cell_type":"code","source":["dbutils.widgets.removeAll()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2f8a6c7-89cb-4dd8-8a8d-611167c17414"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Learning More\n\nWe like to encourage you to explore the documentation to learn more about the various features of the Databricks platform and notebooks.\n* <a href=\"https://docs.azuredatabricks.net/user-guide/index.html\" target=\"_blank\">User Guide</a>\n* <a href=\"https://docs.azuredatabricks.net/user-guide/notebooks/index.html\" target=\"_blank\">User Guide / Notebooks</a>\n* <a href=\"https://docs.azuredatabricks.net/administration-guide/index.html\" target=\"_blank\">Administration Guide</a>\n* <a href=\"https://docs.azuredatabricks.net/api/index.html\" target=\"_blank\">REST API</a>\n* <a href=\"https://docs.azuredatabricks.net/release-notes/index.html\" target=\"_blank\">Release Notes</a>\n* <a href=\"https://docs.azuredatabricks.net\" target=\"_blank\">And much more!</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"419766f7-6eb7-4f57-a3c2-e9f8385b9ea5"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2810252e-d4a6-4dcb-902f-0f054119b111"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f05bafb-362e-4553-b77d-9833ca8c959b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3a99158-385d-4e44-9c4a-b406517946e3"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Databricks Environment","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840250}},"nbformat":4,"nbformat_minor":0}
