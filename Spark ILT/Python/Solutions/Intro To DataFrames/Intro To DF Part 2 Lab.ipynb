{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de2fb4d0-5a1d-464a-96b8-6dded34934ba"}}},{"cell_type":"markdown","source":["# Introduction to DataFrames, Lab #2\n## Washingtons and Marthas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca900dc7-ccaa-4b81-b7a5-f70f0f131977"}}},{"cell_type":"markdown","source":["-sandbox\n##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Instructions\n\nThis data was captured in the August before the 2016 presidential election.\n\nAs a result, articles about the candidates were very popular.\n\nFor this exercise, you will...\n0. Filter the result to the **en** Wikipedia project.\n0. Find all the articles where the name of the article **ends** with **_Washington** (presumably \"George Washington\", \"Martha Washington\", etc)\n0. Return all records as an array to the Driver.\n0. Assign your array of Washingtons (the return value of your action) to the variable `washingtons`.\n0. Calculate the sum of requests for the Washingtons and assign it to the variable `totalWashingtons`. <br/>\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** We've not yet covered `DataFrame` aggregation techniques, so for this exercise use the array of records you have just obtained.\n\n** Bonus **\n\nRepeat the exercise for the Marthas\n0. Filter the result to the **en** Wikipedia project.\n0. Find all the articles where the name of the article **starts** with **Martha_** (presumably \"Martha Washington\", \"Martha Graham\", etc)\n0. Return all records as an array to the Driver.\n0. Assign your array of Marthas (the return value of your action) to the variable `marthas`.\n0. Calculate the sum of requests for the Marthas and assign it to the variable `totalMarthas`.<br/>\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** We've not yet covered `DataFrame` aggregation techniques, so for this exercise use the array of records you have just obtained.\n0. But you cannot do it the same way twice:\n   * In the filter, don't use the same conditional method as the one used for the Washingtons.\n   * Don't use the same action as used for the Washingtons.\n\n**Testing**\n\nRun the last cell to verify that your results are correct.\n\n**Hints**\n* <img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Make sure to include the underscore in the condition.\n* The actions we've explored for extracting data include:\n  * `first()`\n  * `collect()`\n  * `head()`\n  * `take(n)`\n* The conditional methods used with a `filter(..)` include:\n  * equals\n  * not-equals\n  * starts-with\n  * and there are others - remember, the `DataFrames` API is built upon an SQL engine.\n* There shouldn't be more than 1000 records for either the Washingtons or the Marthas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21824f4d-a70e-4126-81cc-3adb4694ce81"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5516a15a-1545-4cc4-812e-1ebd0b0cd340"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"356b72c3-45cb-4e68-9946-107907c640c1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Show Your Work"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16206a3d-eaa4-4ace-b9ff-1c35e3083ced"}}},{"cell_type":"code","source":["(source, sasEntity, sasToken) = getAzureDataSource()\nspark.conf.set(sasEntity, sasToken)\n\nparquetDir = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63dec938-45db-4ed1-a3e9-0e276339a499"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# ANSWER\n\nfrom pyspark.sql.functions import *\n\nparquetDir = \"/mnt/training/wikipedia/pagecounts/staging_parquet_en_only_clean/\"\n\nwashingtons = (spark.read\n  .parquet(parquetDir)\n  .filter( col(\"project\") == \"en\")\n  .filter( col(\"article\").endswith(\"_Washington\") )\n  #.filter( col(\"article\").like(\"%\\\\_Washington\") )\n  .collect()\n  #.take(1000)\n)\ntotalWashingtons = 0\n\nfor washington in washingtons:\n  totalWashingtons += washington[\"requests\"]\n\nprint(f\"Total Washingtons: {len(washingtons):,}\")\nprint(f\"Total Washington Requests: {totalWashingtons:,}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54388aa4-8c79-4949-82ad-42811359ab6f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# ANSWER\n# BEST ANSWER - this is how you would do it in production\n\nfrom pyspark.sql.functions import *  # sum(), count()\n\nparquetDir = \"/mnt/training/wikipedia/pagecounts/staging_parquet_en_only_clean/\"\n\nstats = (spark.read\n  .parquet(parquetDir)\n  .filter((col(\"project\") == \"en\") & col(\"article\").endswith(\"_Washington\"))\n  .select(sum(\"requests\"), count(\"*\"))\n  .first())\n\ntotalWashingtons = stats[0]\nwashingtonCount = stats[1]\n\nprint(f\"Total Washingtons: {washingtonCount}\" )\nprint(f\"Total Washingtons Requests: {totalWashingtons}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b2c4e01-e7f9-47e7-89b8-f2c8f4dbbb6f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# ANSWER\n\nfrom pyspark.sql.functions import *\n\nmarthas = (spark.read\n  .parquet(parquetDir)\n  .filter( col(\"project\") == \"en\")\n  #.filter( col(\"article\").startswith(\"Martha_\") )\n  .filter( col(\"article\").like(\"Martha\\\\_%\") )\n  #.collect()\n  .take(1000)\n)\ntotalMarthas = 0\n\nfor martha in marthas:\n  totalMarthas += martha[\"requests\"]\n\nprint(f\"Total Marthas: {len(marthas):,}\")\nprint(f\"Total Marthas Requests: {totalMarthas:,}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2ade2d0-e6ad-43a5-b7a4-9d89cf285af4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b06a3ba8-2901-4718-a8db-532a37e64dd5"}}},{"cell_type":"code","source":["print(f\"Total Washingtons: {len(washingtons):,}\")\nprint(f\"Total Washington Requests: {totalWashingtons:,}\")\n\nexpectedCount = 466\nassert len(washingtons) == expectedCount, \"Expected \" + str(expectedCount) + \" articles but found \" + str( len(washingtons) )\n\nexpectedTotal = 3266\nassert totalWashingtons == expectedTotal, \"Expected \" + str(expectedTotal) + \" requests but found \" + str(totalWashingtons)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d78c970d-1c19-49f4-81e1-cdece97beeea"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(f\"Total Marthas: {len(marthas):,}\")\nprint(f\"Total Marthas Requests: {totalMarthas:,}\")\n\nexpectedCount = 146\nassert len(marthas) == expectedCount, \"Expected \" + str(expectedCount) + \" articles but found \" + str( len(marthas) )\n\nexpectedTotal = 708\nassert totalMarthas == expectedTotal, \"Expected \" + str(expectedTotal) + \" requests but found \" + str(totalMarthas)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"335fd3cf-839b-45c8-80a5-0a0cb297c744"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb085bea-67b9-474b-9abd-6cb568423657"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70e91ee3-6007-43b9-889d-bfc2476f5e26"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46d94083-00b8-4639-a79f-b27d5897f43e"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Intro To DF Part 2 Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577839847}},"nbformat":4,"nbformat_minor":0}
