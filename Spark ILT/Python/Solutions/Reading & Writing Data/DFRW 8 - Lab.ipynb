{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d72e7c8-88ba-4ad3-899f-8f893221e5ff"}}},{"cell_type":"markdown","source":["# Reading Data Lab\n* The goal of this lab is to put into practice some of what you have learned about reading data with Apache Spark.\n* The instructions are provided below along with empty cells for you to do your work.\n* At the bottom of this notebook are additional cells that will help verify that your work is accurate."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5bf2503-bd72-473e-a1e1-0fe243cdde3c"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Instructions\n0. Start with the file **dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv**, some random file you haven't seen yet.\n0. Read in the data and assign it to a `DataFrame` named **testDF**.\n0. Run the last cell to verify that the data was loaded correctly and to print its schema.\n0. The one untestable requirement is that you should be able to create the `DataFrame` and print its schema **without** executing a single job.\n\n**Note:** For the test to pass, the following columns should have the specified data types:\n * **prev_id**: integer\n * **curr_id**: integer\n * **n**: integer\n * **prev_title**: string\n * **curr_title**: string\n * **type**: string"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2a33da1-c21e-40e9-9d9d-eb46e3de2216"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4fd6bf1-eaa2-49e6-bbd5-62f6ef20a9f2"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89433c6f-6ab1-4e25-ab79-418ecb3c5231"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Show Your Work"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f63dd6fc-36d2-42f2-94f8-266a3e505db6"}}},{"cell_type":"code","source":["# ANSWER\n\n# The students will actually need to do this in two steps.\nfileName = \"dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv\"\n\n# The first step will be to use inferSchema = true \n# It's the only way to figure out what the column and data types are\n(spark.read\n  .option(\"sep\", \"\\t\")\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .csv(fileName)\n  .printSchema()\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2991e1b-5fe0-4237-af21-77d31e65316c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# ANSWER\n\nfrom pyspark.sql.types import *\n\n# The second step is to create the schema\nschema = StructType([\n    StructField(\"prev_id\", IntegerType(), False),\n    StructField(\"curr_id\", IntegerType(), False),\n    StructField(\"n\", IntegerType(), False),\n    StructField(\"prev_title\", StringType(), False),\n    StructField(\"curr_title\", StringType(), False),\n    StructField(\"type\", StringType(), False)\n])\n\nfileName = \"dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv\"\n\n#The third step is to read the data in with the user-defined schema\ntestDF = (spark.read\n  .option(\"sep\", \"\\t\")\n  .option(\"header\", \"true\")\n  .schema(schema)\n  .csv(fileName)\n)\n\ntestDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e0d649a-1335-400f-a6b3-cc2a7d6cec41"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly.\n\n**Remember:** This should execute without triggering a single job."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26fc6370-b3a5-4dc5-a50c-ff7ca6777cae"}}},{"cell_type":"code","source":["testDF.printSchema()\n\ncolumns = testDF.dtypes\nassert len(columns) == 6, \"Expected 6 columns but found \" + str(len(columns))\n\nassert columns[0][0] == \"prev_id\",    \"Expected column 0 to be \\\"prev_id\\\" but found \\\"\" + columns[0][0] + \"\\\".\"\nassert columns[0][1] == \"int\",        \"Expected column 0 to be of type \\\"int\\\" but found \\\"\" + columns[0][1] + \"\\\".\"\n\nassert columns[1][0] == \"curr_id\",    \"Expected column 1 to be \\\"curr_id\\\" but found \\\"\" + columns[1][0] + \"\\\".\"\nassert columns[1][1] == \"int\",        \"Expected column 1 to be of type \\\"int\\\" but found \\\"\" + columns[1][1] + \"\\\".\"\n\nassert columns[2][0] == \"n\",          \"Expected column 2 to be \\\"n\\\" but found \\\"\" + columns[2][0] + \"\\\".\"\nassert columns[2][1] == \"int\",        \"Expected column 2 to be of type \\\"int\\\" but found \\\"\" + columns[2][1] + \"\\\".\"\n\nassert columns[3][0] == \"prev_title\", \"Expected column 3 to be \\\"prev_title\\\" but found \\\"\" + columns[3][0] + \"\\\".\"\nassert columns[3][1] == \"string\",     \"Expected column 3 to be of type \\\"string\\\" but found \\\"\" + columns[3][1] + \"\\\".\"\n\nassert columns[4][0] == \"curr_title\", \"Expected column 4 to be \\\"curr_title\\\" but found \\\"\" + columns[4][0] + \"\\\".\"\nassert columns[4][1] == \"string\",     \"Expected column 4 to be of type \\\"string\\\" but found \\\"\" + columns[4][1] + \"\\\".\"\n\nassert columns[5][0] == \"type\",       \"Expected column 5 to be \\\"type\\\" but found \\\"\" + columns[5][0] + \"\\\".\"\nassert columns[5][1] == \"string\",     \"Expected column 5 to be of type \\\"string\\\" but found \\\"\" + columns[5][1] + \"\\\".\"\n\nprint(\"Congratulations, all tests passed... that is if no jobs were triggered :-)\\n\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4754f22f-b541-45a2-852e-0bc07a0ddb03"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8802f257-d316-4ac1-b46c-64efb45f46c0"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6748d638-3b08-44f0-a698-354c00b23a55"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a05d379-202a-4d58-a745-6c1b883a4e75"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DFRW 8 - Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840032}},"nbformat":4,"nbformat_minor":0}
