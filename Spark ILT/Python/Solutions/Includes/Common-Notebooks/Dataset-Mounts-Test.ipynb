{"cells":[{"cell_type":"markdown","source":["d\n# Dataset-Mounts-Test\nThe purpose of this notebook is to faciliate testing of our systems."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20ff819d-dc78-4c96-b604-efce3ed3984a"}}},{"cell_type":"code","source":["spark.conf.set(\"com.databricks.training.module-name\", \"dataset-mounts-test\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9814ff36-da80-43e5-9502-749d6e16b755"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run ./Dataset-Mounts"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57c6577f-6564-4666-b4b1-48c3fa7bc2da"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n\nval testStart = System.currentTimeMillis\nval mountPointBase = \"/mnt/training-test\"\n\ndef unmount(mountPoint:String):Unit = {\n  try {\n    dbutils.fs.unmount(mountPoint)\n  } catch {\n    case e:Exception => println(s\"Not mounted: $mountPoint\")\n  }\n}\n\ndef testRegion(regionType:String, regionName:String, mapper: (String) => (String,Map[String,String])):Unit = {\n  val start = System.currentTimeMillis\n  \n  val (source, extraConfigs) = mapper(regionName)\n  val mountPoint = s\"$mountPointBase-${regionType.toLowerCase}-$regionName\"\n  println(s\"\"\"\\nTesting the $regionType region $regionName ($mountPoint)\"\"\")\n\n  mountSource(true, false, mountPoint, source, extraConfigs)\n  Thread.sleep(5*1000) // give it a second\n  validateDatasets(mountPoint)\n  \n  val duration = (System.currentTimeMillis - start) / 1000.0\n  println(f\"...all tests passed in $duration%1.2f seconds!\")\n}\n\ndef validateDataset(mountPoint:String, target:String):Unit = {\n  val map = scala.collection.mutable.Map[String,(Long,Long)]()\n  for (file <- dbutils.fs.ls(s\"/mnt/training/$target\")) {\n    map.put(file.name, (file.size, -1L))\n  }\n\n  val path = s\"$mountPoint/$target\"\n  for (file <- dbutils.fs.ls(path)) {\n      if (map.contains(file.name)) {\n        val (sizes, _) = map(file.name)\n        map.put(file.name, (sizes, file.size))\n      } else {\n        map.put(file.name, (-1, file.size))\n      }\n  }\n  \n  var errors = \"\"\n  for (key <- map.keySet) {\n    val (sizeA, sizeB) = map(key)\n    if (sizeA == sizeB) {\n      // Everything matches up... no issue here.\n    } else if (sizeA == -1) {\n      if (!key.endsWith(\"_$folder$\"))\n        errors += s\"Extra file: $path$key\\n\"\n    } else if (sizeB == -1) {\n      errors += s\"Missing file: $path$key\\n\"\n    }\n  }\n  \n  errors = errors.trim()\n  if (errors != \"\") {\n    println(errors)\n    throw new IllegalStateException(s\"Errors were found while processing $path\")\n  }\n}\n\n\ndef validateDatasets(mountPoint:String) {\n  val paths = List(\n    \"\",\n    \"301/\",\n    \"Chicago-Crimes-2018.csv\",\n    \"City-Data.parquet/\",\n    \"EDGAR-Log-20170329/\",\n    \"UbiqLog4UCI/\",\n    \"_META/\",\n    \"adventure-works/\",\n    \"airbnb/\",\n    \"airbnb-sf-listings.csv\",\n    \"asa/\",\n    \"auto-mpg.csv\",\n    \"bigrams/\",\n    \"bikeSharing/\",\n    \"bostonhousing/\",\n    \"cancer/\",\n    \"countries/\",\n    \"crime-data-2016/\",\n    \"data/\",\n    \"data-cleansing/\",\n    \"databricks-blog.json\",\n    \"databricks-datasets/\",\n    \"dataframes/\",\n    \"day-of-week/\",\n    \"definitive-guide/\",\n    \"dl/\",\n    \"gaming_data/\",\n    \"global-sales/\",\n    \"graphx-demo/\",\n    \"initech/\",\n    \"ip-geocode.parquet/\",\n    \"iris/\",\n    \"mini_newsgroups/\",\n    \"mnist/\",\n    \"movie-reviews/\",\n    \"movielens/\",\n    \"movies/\",\n    \"online_retail/\",\n    \"philadelphia-crime-data-2015-ytd.csv\",\n    \"purchases.txt\",\n    \"sensor-data/\",\n    \"ssn/\",\n    \"stopwords\",\n    \"structured-streaming/\",\n    \"test.log\",\n    \"tom-sawyer/\",\n    \"tweets.txt\",\n    \"twitter/\",\n    \"wash_dc_crime_incidents_2013.csv\",\n    \"wash_dc_crime_incidents_2015-10-03-to-2016-10-02.csv\",\n    \"weather/\",\n    \"wikipedia/\",\n    \"wine.parquet/\",\n    \"word-game-dict.txt\",\n    \"zip3state.csv\",\n    \"zips.json\"\n  )\n  for (path <- paths) {\n    validateDataset(mountPoint, path)\n  }\n}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"313649b3-b89d-4e89-b5bb-f18034047092"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\nval awsRegions=List(\n  \"us-west-2\",\n  \"ap-northeast-1\",\n  \"ap-northeast-2\",\n  \"ap-south-1\",\n  \"ap-southeast-1\",\n  \"ap-southeast-2\",\n  \"ca-central-1\",\n  \"eu-central-1\",\n  \"eu-west-1\",\n  \"eu-west-2\",\n  \"eu-west-3\",\n  \"sa-east-1\",\n  \"us-east-1\",\n  \"us-east-2\"\n).map(_.toLowerCase())\n\nval azureRegions=List(\n \"AustraliaCentral\",\n \"AustraliaCentral2\",\n \"AustraliaEast\",\n \"AustraliaSoutheast\",\n \"CanadaCentral\",\n \"CanadaEast\",\n \"CentralIndia\",\n \"CentralUS\",\n \"EastAsia\",\n \"EastUS\",\n \"EastUS2\",\n \"JapanEast\",\n \"JapanWest\",\n \"NorthCentralUS\",\n \"NorthCentralUS\",\n \"NorthEurope\",\n \"SouthCentralUS\",\n \"SouthCentralUS\",\n \"SouthIndia\",\n \"SoutheastAsia\",\n \"UKSouth\",\n \"UKWest\",\n \"WestCentralUS\",  // Azure Databricks isn't available in region, but we historically copied data here anyway.\n \"WestEurope\",\n \"WestIndia\",\n \"WestUS\",\n \"WestUS2\"\n).map(_.toLowerCase())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f08b49d-abe4-4aa9-83c4-fb84ed54b34a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\nfor (region <- awsRegions) {\n  testRegion(\"AWS\", region, getAwsMapping _)\n}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"261abc08-4646-4ccd-8033-51f99d9a08d7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\nfor mount in (mount[0] for mount in dbutils.fs.mounts() if \"training-test\" in mount[0]):\n  dbutils.fs.unmount(mount)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e6df70a-8f70-4065-b9a0-09f6951a17ec"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\nfor (region <- azureRegions) {\n  testRegion(\"Azure\", region, getAzureMapping _)\n}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4619a1fa-47fd-47d5-8887-5f13d4adae02"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\nprintln(f\"...all tests passed in ${(System.currentTimeMillis - testStart) / 1000.0 / 60.0}%1.2f minutes!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cab0c337-28fd-4771-b7d8-563b93c518bb"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\nfor mount in (mount[0] for mount in dbutils.fs.mounts() if \"training-test\" in mount[0]):\n  dbutils.fs.unmount(mount)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28451383-4dd0-4f02-a1cf-5ef0336d8a7e"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Dataset-Mounts-Test","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577839995}},"nbformat":4,"nbformat_minor":0}
