{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24c05eb1-11ad-4907-9f57-9abf1445b6f7"}}},{"cell_type":"markdown","source":["# Reading and Writing Data - Azure Data Lake Storage Gen2\n**Technical Accomplishments:**\n- Access an Azure Data Lake Storage Gen2 filesystem by mounting to DBFS\n\n**Requirements:**\n- ADLS Gen2 storage account in the same region as your Azure Databricks workspace\n- A service principal with delegated permissions OR storage account access key\n\nYou will create Gen2 storage account and access it using a service principal in the steps below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"158bb0d4-eca5-4e6c-bfdc-ac12b70c5aae"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a93da7b-87f5-4ae6-9f88-357aa82b7eaf"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80b0508d-9341-4965-8582-45f66e724397"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Azure Data Lake Storage Gen2 (ADLS Gen2)\n\nAzure Data Lake Storage Gen2 is a next-generation data lake solution for big data analytics.\n\nADLS Gen2 builds ADLS Gen1 capabilities - such as file system semantics, file-level security, and scale - \n\ninto Azure Blob Storage, with its low-cost tiered storage, high availability, and disaster recovery features."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b013f47d-e871-4c56-ae19-bcc7bc9bba41"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Create Service Principal\nYou can access an ADLS Gen2 filesystem by using a **service principal** or by using the **storage account access key** directly.\n\nHowever, if you want to mount the filesystem to DBFS, this requires OAuth 2.0 authentication, which means you'll have to use a **service principal**.\n\nAs you work through the following steps, record the **Directory ID**, **Application ID**, and **Secret** in the cell below:\n1. In Azure Active Directory, go to Properties. Note the **Directory ID**\n1. Go to App Registrations and create a new application registration\n   * e.g. airlift-app-registration, Web app/API, https://can-be-literally-anything.com\n1. Note the **Application ID**\n1. Go to Certificates & Secrets and create a new client **secret** and copy its value"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d12a891-5567-4855-a083-3ea23ede4ad7"}}},{"cell_type":"code","source":["# TODO\ndirectoryID = FILL_IN\napplicationID = FILL_IN\nkeyValue = FILL_IN"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"935e1056-c889-4626-bcd0-9563774be472"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Create Storage Account\n\nFollow these steps to <a href=\"https://docs.microsoft.com/en-us/azure/storage/data-lake-storage/quickstart-create-account\" target=\"_blank\">create your ADLS Gen2 storage account</a>.\n\nAs you work through the following steps, record the **Storage Account Name** and **File System Name** in the cell below:\n0. Access the Azure Portal > Create a new resource > Storage account\n0. Make sure to specify the correct *Resource Group* and *Region*, and use any unique string for the **Storage Account Name**  \n  - Ensure the storage account is in the same region as your Azure Databricks workspace\n0. Go to the **Advanced Tab** and **enable Hierarchical NameSpace**\n0. Create a Data Lake Gen2 file system on the storage account and enter the **File System Name** in the cell below.\n0. Under Access control (IAM) add a **Role assignment**, where the role is **Storage Blob Data Contributor (Preview)** assigned to the App Registration previously created"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"feab0c0e-8284-4020-b5c9-34b226cb8ec9"}}},{"cell_type":"code","source":["# TODO\nstorageAccountName = FILL_IN.VALUE\nfileSystemName = FILL_IN.VALUE"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33bd642a-a22e-4497-922f-b94a3f9c6029"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Mount ADLS Gen2 filesystem to DBFS\n\nUse **`dbutils.fs.mount`** to <a href=\"https://docs.databricks.com/spark/latest/data-sources/azure/azure-datalake-gen2.html#mount-an-adls-filesystem-to-dbfs-using-a-service-principal-and-oauth-2-0\" target=\"_blank\">mount this filesystem</a> to DBFS."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de1e228c-24ae-471b-937c-8fc52ef59909"}}},{"cell_type":"code","source":["configs = {\n  \"fs.azure.account.auth.type\": \"OAuth\",\n  \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n  \"fs.azure.account.oauth2.client.id\": applicationID,\n  \"fs.azure.account.oauth2.client.secret\": keyValue,\n  \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/{}/oauth2/token\".format(directoryID)\n}\n\nmountPoint = f\"/mnt/{username}-{fileSystemName}\"\nsource = f\"abfss://{fileSystemName}@{storageAccountName}.dfs.core.windows.net/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca350fab-0404-4b7a-a166-22770aba55ed"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.mount(\n  source = source,\n  mount_point = mountPoint,\n  extra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7940b3d8-16ad-494a-aab8-eaea339d5360"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Access Your Files\nNow, you can access files in your container as if they were local files!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06e0e571-f5ca-4599-a3bf-e88a509dfb5d"}}},{"cell_type":"code","source":["files = dbutils.fs.ls(mountPoint)\n\ndisplay(files)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14875472-b297-4b20-9283-5a5ad7ef0115"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["wikiEditsDF = spark.read.json(f\"{mountPoint}/wikipedia/edits/snapshot-2016-05-26.json\")\n\ndisplay(wikiEditsDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df0da0ab-e29f-421a-ab13-ab45aae21908"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["(wikiEditsDF.write\n  .mode(\"overwrite\")\n  .format(\"delta\")\n  .partitionBy(\"channel\")\n  .save(f\"{mountPoint}/wikiEdits\")\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7bbb432-e23a-467b-b9d5-529c16074b38"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Unmount a Mount Point\nUse **`dbutils.fs.unmount`** to unmount a mount point."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e2eed89-66ed-480d-bebe-bb06fe132e14"}}},{"cell_type":"code","source":["dbutils.fs.unmount(mountPoint)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69b45a42-536a-4e60-8be9-d6cbc46e78e1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"381cf582-cc7a-4c00-b559-c68e87304c16"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0845753-4f62-4f05-84b4-13442c40f578"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0383ec6e-1dc5-4d23-8095-3430a9314e8b"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"MSA 2 - ADLS Gen 2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840444}},"nbformat":4,"nbformat_minor":0}
