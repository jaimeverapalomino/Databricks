{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51ca3e5c-ddba-486a-96ff-4506dcc38626"}}},{"cell_type":"markdown","source":["# Reading Data - Parquet Files\n\n**Technical Accomplishments:**\n- Introduce the Parquet file format.\n- Read data from:\n  - Parquet files without a schema.\n  - Parquet files with a schema."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cca8310c-90fb-4650-ad9f-804b088ec51e"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1670351a-514d-4586-90cc-52b727238e90"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22ba3f1b-6820-44b2-80ce-75c3c98e4b3a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n<div style=\"float:right; margin-right:1em\">\n  <img src=\"https://parquet.apache.org/assets/img/parquet_logo.png\"><br>\n  <a href=\"https://parquet.apache.org/\" target=\"_blank\">https&#58;//parquet.apache.org</a>\n</div>\n\n##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Reading from Parquet Files\n\n<strong style=\"font-size:larger\">\"</strong>Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.<strong style=\"font-size:larger\">\"</strong><br>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"912d1931-1d08-4ed0-8249-18bc16c9807c"}}},{"cell_type":"markdown","source":["-sandbox\n### About Parquet Files\n* Free & Open Source.\n* Increased query performance over row-based data stores.\n* Provides efficient data compression.\n* Designed for performance on large data sets.\n* Supports limited schema evolution.\n* Is a splittable \"file format\".\n* A <a href=\"https://en.wikipedia.org/wiki/Column-oriented_DBMS\" target=\"_blank\">Column-Oriented</a> data store\n\n&nbsp;&nbsp;&nbsp;&nbsp;** Row Format ** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Column Format**\n\n<table style=\"border:0\">\n\n  <tr>\n    <th>ID</th><th>Name</th><th>Score</th>\n    <th style=\"border-top:0;border-bottom:0\">&nbsp;</th>\n    <th>ID:</th><td>1</td><td>2</td>\n    <td style=\"border-right: 1px solid #DDDDDD\">3</td>\n  </tr>\n\n  <tr>\n    <td>1</td><td>john</td><td>4.1</td>\n    <td style=\"border-top:0;border-bottom:0\">&nbsp;</td>\n    <th>Name:</th><td>john</td><td>mike</td>\n    <td style=\"border-right: 1px solid #DDDDDD\">sally</td>\n  </tr>\n\n  <tr>\n    <td>2</td><td>mike</td><td>3.5</td>\n    <td style=\"border-top:0;border-bottom:0\">&nbsp;</td>\n    <th style=\"border-bottom: 1px solid #DDDDDD\">Score:</th>\n    <td style=\"border-bottom: 1px solid #DDDDDD\">4.1</td>\n    <td style=\"border-bottom: 1px solid #DDDDDD\">3.5</td>\n    <td style=\"border-bottom: 1px solid #DDDDDD; border-right: 1px solid #DDDDDD\">6.4</td>\n  </tr>\n\n  <tr>\n    <td style=\"border-bottom: 1px solid #DDDDDD\">3</td>\n    <td style=\"border-bottom: 1px solid #DDDDDD\">sally</td>\n    <td style=\"border-bottom: 1px solid #DDDDDD; border-right: 1px solid #DDDDDD\">6.4</td>\n  </tr>\n\n</table>\n\nSee also\n* <a href=\"https://parquet.apache.org/\" target=\"_blank\">https&#58;//parquet.apache.org</a>\n* <a href=\"https://en.wikipedia.org/wiki/Apache_Parquet\" target=\"_blank\">https&#58;//en.wikipedia.org/wiki/Apache_Parquet</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"913edc54-f6be-4ca0-abd1-db165c70189c"}}},{"cell_type":"markdown","source":["### Data Source\n\nThe data for this example shows the number of requests to Wikipedia's mobile and desktop websites (<a href=\"https://dumps.wikimedia.org/other/pagecounts-raw\" target=\"_blank\">from Wikipedia</a>). \n\nThe original file was converted to a Parquet file and made available for us at **/mnt/training/wikipedia/pageviews/pageviews_by_second.parquet/**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"489b3d02-80d0-4692-b15c-a5ec5a389429"}}},{"cell_type":"code","source":["%fs ls /mnt/training/wikipedia/pageviews/pageviews_by_second.parquet/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea9f766e-8a25-4915-a9cb-cea4ab3b7bab"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Read in the Parquet Files\n\nTo read in this files, we will specify the location of the parquet directory."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f40266fe-46ca-4d94-aa98-5e99bc7b57af"}}},{"cell_type":"code","source":["parquetFile = \"/mnt/training/wikipedia/pageviews/pageviews_by_second.parquet/\"\n\n(spark.read              # The DataFrameReader\n  .parquet(parquetFile)  # Creates a DataFrame from Parquet after reading in the file\n  .printSchema()         # Print the DataFrame's schema\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd965798-9ca1-4837-9b9c-37e51936f595"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Review: Reading from Parquet Files\n* We do not need to specify the schema - the column names and data types are stored in the parquet files.\n* Only one job is required to **read** that schema from the parquet file's metadata.\n* Unlike the CSV or JSON readers that have to load the entire file and then infer the schema, the parquet reader can \"read\" the schema very quickly because it's reading that schema from the metadata."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73b1d12d-4ba6-4fcc-b34a-0d6155f94d59"}}},{"cell_type":"markdown","source":["### Read in the Parquet Files w/Schema\n\nIf you want to avoid the extra job entirely, we can, again, specify the schema even for parquet files:\n\n** *WARNING* ** *Providing a schema may avoid this one-time hit to determine the `DataFrame's` schema.*  \n*However, if you specify the wrong schema it will conflict with the true schema and will result in an analysis exception at runtime.*"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"057c44b7-453c-4b82-81c2-69ec109a3f7c"}}},{"cell_type":"code","source":["# Required for StructField, StringType, IntegerType, etc.\nfrom pyspark.sql.types import *\n\nparquetSchema = StructType(\n  [\n    StructField(\"timestamp\", StringType(), False),\n    StructField(\"site\", StringType(), False),\n    StructField(\"requests\", IntegerType(), False)\n  ]\n)\n\n(spark.read               # The DataFrameReader\n  .schema(parquetSchema)  # Use the specified schema\n  .parquet(parquetFile)   # Creates a DataFrame from Parquet after reading in the file\n  .printSchema()          # Print the DataFrame's schema\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f69bd87-a506-4d77-aa65-d8f329efaad8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's take a look at some of the other details of the `DataFrame` we just created for comparison sake."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da12671c-6c4d-48b4-97a0-b3cb61e25f10"}}},{"cell_type":"code","source":["parquetDF = spark.read.schema(parquetSchema).parquet(parquetFile)\n\nprint(\"Partitions: \" + str(parquetDF.rdd.getNumPartitions()) )\nprintRecordsPerPartition(parquetDF)\nprint(\"-\"*80)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d8b41c6-a6e6-4676-9e40-51686e27d3e3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["In most/many cases, people do not provide the schema for Parquet files because reading in the schema is such a cheap process.\n\nAnd lastly, let's peek at the data:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a26c730-d018-47c4-80ed-ba3bd70c451a"}}},{"cell_type":"code","source":["display(parquetDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c9a4939-9177-4632-8326-76abe4fdcd65"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22f58b12-6049-4d06-9267-ee2dd7d80c9c"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c12fb5c8-f64b-4fec-a1c3-f1a2e7db1634"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Next Steps\n\n* [Reading Data #1 - CSV]($./Reading Data 1 - CSV)\n* Reading Data #2 - Parquet\n* [Reading Data #3 - Tables]($./Reading Data 3 - Tables)\n* [Reading Data #4 - JSON]($./Reading Data 4 - JSON)\n* [Reading Data #5 - Text]($./Reading Data 5 - Text)\n* [Reading Data #6 - JDBC]($./Reading Data 6 - JDBC)\n* [Reading Data #7 - Summary]($./Reading Data 7 - Summary)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b43abab-2ab4-4e4d-b185-3c9b92e27900"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7852b9da-de06-44a7-b8df-c662f167f455"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DFRW 2 - Parquet","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840466}},"nbformat":4,"nbformat_minor":0}
