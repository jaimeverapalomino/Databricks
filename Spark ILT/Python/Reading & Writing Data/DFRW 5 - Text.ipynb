{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdc687cf-d34c-4e59-9688-0cd2d6857650"}}},{"cell_type":"markdown","source":["# Reading Data - Text Files\n\n**Technical Accomplishments:**\n- Reading data from a simple text file"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cac84bf8-13c8-4994-8fe4-4f62002d0940"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38351db3-c091-4f74-b10c-d7f3e95af260"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2623baeb-9bfd-4bc5-8f6e-4972247c63eb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Reading from Fixed-Width Text File\n\nWe can read in just about any file when each record is delineated only by a new line just as we saw with CSV and JSON (or rather JSON-Lines), formats.\n\nTo accomplish this, we can use `DataFrameReader.text(..)` which gives a `DataFrame` with just one column named **value** of type **string**.\n\nThe difference is that we now need to take responsibility for parsing out the data in each \"column\" ourselves.\n\nOne of the more common use cases is fixed-width files or even Apache's HTTP Access Logs. In the first case, it would require a sequence of substrings. In the second, a sequence of regular expressions would be a better solution to extract the value of each column. In either case, additional transformations are required - which we will go into later.\n\nFor this example, we are going to create a `DataFrame` from the full text of the book *The Adventures of Tom Sawyer* by Mark Twain."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e9e8b6d-11bb-43fa-918c-2c62588b8b57"}}},{"cell_type":"code","source":["%fs ls /mnt/training/tom-sawyer/tom.txt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8fee9e9d-9cfd-483b-b0dc-1eb6eb4e74b5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%fs head /mnt/training/tom-sawyer/tom.txt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97375153-4673-46e8-b0fd-fc9d28ff2796"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["textFile = \"/mnt/training/tom-sawyer/tom.txt\"\n\ntextDF = (spark.read        # The DataFrameReader\n          .text(textFile)   # Creates a DataFrame from raw text after reading in the file\n)\n\ntextDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d6954e7-7fc9-42a8-8049-f4a3337bdb8a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["And with the `DataFrame` created, we can view the data, one record for each line in the text file."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c780a85-b5b4-4ecc-bbd9-f9820bcb4e3b"}}},{"cell_type":"code","source":["display(textDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4caced91-4151-40f6-912a-e0654d465d87"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["As simple as this example is, it's also the premise for loading more complex text files like fixed-width text files.\n\nWe will see later exactly how to do this, but for each line that is read in, it's simply a matter of a couple of more transformations (like substring-ing values) to convert each line into something more meaningful.\n\nLet's take a look at some of the other details of the `DataFrame` we just created for comparison sake."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2b5ebdc-febe-43e1-ae99-815fef4d700a"}}},{"cell_type":"code","source":["print(\"Partitions: \" + str(textDF.rdd.getNumPartitions()))\nprintRecordsPerPartition(textDF)\nprint(\"-\"*80)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5c2aafe-9e2b-40ce-9f52-1aab1cd6c491"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e97ddc5c-5ed7-4ff7-818b-c1aaffcf027f"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3bee094-1669-492f-8243-58506b1f12ec"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Next Steps\n\n* [Reading Data #1 - CSV]($./Reading Data 1 - CSV)\n* [Reading Data #2 - Parquet]($./Reading Data 2 - Parquet)\n* [Reading Data #3 - Tables]($./Reading Data 3 - Tables)\n* [Reading Data #4 - JSON]($./Reading Data 4 - JSON)\n* Reading Data #5 - Text\n* [Reading Data #6 - JDBC]($./Reading Data 6 - JDBC)\n* [Reading Data #7 - Summary]($./Reading Data 7 - Summary)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"775bf100-ff0b-40ee-9b2e-ed7caffb1eec"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c19e684f-0b10-48e5-88ee-71f8069c655a"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DFRW 5 - Text","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840722}},"nbformat":4,"nbformat_minor":0}
