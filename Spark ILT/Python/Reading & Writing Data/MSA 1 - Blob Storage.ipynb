{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09dec1cd-ae4f-4a05-a1c3-520fdd84f519"}}},{"cell_type":"markdown","source":["# Reading and Writing Data - Azure Blob Storage\n**Technical Accomplishments:**\n- Access Azure Blob Storage directly using the DataFrame API\n- Access Azure Blob Storage by mounting storage with DBFS\n\n**Requirements:**\n- A Shared Key or Shared Access Signature (for accessing *private* storage accounts)\n\nYou will configure a Shared Key and Shared Access Signature (SAS) in the steps below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4677bc3-4b41-437f-b6ed-b5deb042cfcf"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c1b0dc1-3048-47d3-9718-a283799832de"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"781dc896-0cc6-405d-b68e-54791b081f21"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Azure Blob Storage\nAzure Blob Storage is a service for storing large amounts of unstructured object data, such as text or binary data.\n\nYou can use Blob Storage to expose data publicly to the world, or to store application data privately.\n\nWe will cover two ways you can access files from Azure Blob Storage here."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"552aefb5-9e87-46eb-b079-74b2c0031397"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Method 1: Access Azure Blob Storage Directly\n\nIt is possible to read directly from Azure Blob Storage using the <a href=\"https://docs.databricks.com/spark/latest/data-sources/azure/azure-storage.html#access-azure-blob-storage-using-the-dataframe-api\" target=\"_blank\">Spark API and Databricks APIs</a>.\n\n### Configure Access to a Container Using a Shared Access Signature (SAS)\n\nA <a href=\"https://docs.microsoft.com/en-us/azure/storage/common/storage-dotnet-shared-access-signature-part-1\" target=\"_blank\">Shared Access Signature (SAS)</a> is a great way to grant limited access to objects in your storage account to other clients, without exposing your account key.\n\nRun the cell below to setup a SAS in your notebook by configuring the <a href=\"https://databricks.com/blog/2016/08/15/how-to-use-sparksession-in-apache-spark-2-0.html\" target=\"_blank\">SparkSession</a>.\n\nIn this example, we provide you with a SAS and storage container. Normally, you'll get these values from Azure, and then configure your SparkSession with these values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"906c9814-7dae-4652-bb62-eb09a5133c14"}}},{"cell_type":"code","source":["(source, sasEntity, sasToken) = getAzureDataSource()\n\nspark.conf.set(sasEntity, sasToken)\n\ndisplayHTML(\"\"\"\nRetrieved the following values:\n  <li><b style=\"color:green\">source:</b> <code>{}</code></li>\n  <li><b style=\"color:green\">sasEntity:</b> <code>{}</code></li>\n  <li><b style=\"color:green\">sasToken:</b> <code>{}</code></li><br>\n\nSuccessfully set up a Shared Access Signature (SAS) in your notebook.\n\"\"\".format(source, sasEntity, sasToken))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a433b97-7d1f-4dde-b7b3-07760b974382"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Read Data from Storage Account\nYou can now use standard Spark and Databricks APIs to read from the storage account."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57341159-0cdd-4134-93ab-7f09e9e36b00"}}},{"cell_type":"code","source":["path = source + \"wikipedia/edits/snapshot-2016-05-26.json\"\nwikiEditsDF = spark.read.json(path)\ndisplay(wikiEditsDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbb98bab-9daa-41ac-80f3-bc7c9e1afab2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Method 2: Mount Azure Blob Storage with DBFS\n\nAnother way to access your Azure Blob Storage is to mount your storage with DBFS.\n\nFor this example, you'll create your own Azure <a href=\"https://docs.microsoft.com/en-us/azure/storage/common/storage-quickstart-create-account?tabs=azure-portal\" target=\"_blank\">Storage Account</a> and <a href=\"https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-portal\" target=\"_blank\">Container</a>.\n\nThis time, let's use a <a href=\"https://docs.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key\" target=\"_blank\">Shared Key</a> to authorize requests to the the Storage Account.\n\n### Create an Azure Storage Account and Container\nAs you work through the following steps, record the **Storage Account Name**, **Container Name**, and **Access Key** in the cell below:\n0. Access the Azure Portal > Create a new resource > Storage account\n0. Specify the correct *Resource Group* and *Region*, and use any unique string for the **Storage Account Name**\n0. Access the new Storage account > Access Blobs\n0. Create a New Container using any unique string for the **Container Name**\n0. Retrieve the primary **Access Key** for the new Storage Account"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d64198b-63e9-4703-9676-980022a34683"}}},{"cell_type":"code","source":["# TODO\nstorageAccountName = FILL_IN.VALUE\ncontainerName = FILL_IN.VALUE\nstorageEntity = f\"fs.azure.account.key.{storageAccountName}.blob.core.windows.net\"\naccessKey = FILL_IN.VALUE"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8abdb58b-e9ee-48ac-95ad-848a496bd821"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Mount Container Using DBFS\nUse **`dbutils.fs.mount`** to <a href=\"https://docs.databricks.com/spark/latest/data-sources/azure/azure-storage.html#mount-azure-blob-storage-containers-with-dbfs\" target=\"_blank\">mount this container</a> (or a folder inside this container) to DBFS.\n\nFirst, let's construct the **`sourceURI`** and **`mountPoint`** variables:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e58fb72c-3134-418c-9078-f0475c64b236"}}},{"cell_type":"code","source":["sourceURI = f\"wasbs://{containerName}@{storageAccountName}.blob.core.windows.net/\"\nmountPoint = f\"/mnt/{username}-{containerName}\"\n\ndisplayHTML(f\"\"\"\n  <li><b style=\"color:green\">sourceURI:</b> <code>{sourceURI}</code></li>\n  <li><b style=\"color:green\">mountPoint:</b> <code>{mountPoint}</code></li>\n\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b6850ed-3bba-4886-9eba-272becb6f838"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now we can actually mount our blob:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ed96288-12da-4455-be7e-15187fadfa6c"}}},{"cell_type":"code","source":["dbutils.fs.mount(\n  source = sourceURI, \n  mount_point = mountPoint, \n  extra_configs = {storageEntity: accessKey})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e89cb08-77f3-4c1b-9d18-5baf8ba37ed7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Read and Write Data to Storage Account with DBFS\nNow, you can access files in your container as if they were local files!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89855230-fab3-4e75-80cc-0e6a6fe6b521"}}},{"cell_type":"code","source":["files = dbutils.fs.ls(mountPoint)\n\ndisplay(files)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"298417ce-f843-4a1d-8fed-c0484cc11c98"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Writing to this mount point will write to your storage account."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddbb7e7c-5560-46d9-8322-09413273b1d1"}}},{"cell_type":"code","source":["path = f\"{mountPoint}/wikiEdits.parquet\"\n\n(wikiEditsDF\n  .write\n  .mode(\"overwrite\")\n  .parquet(path))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dba8e489-08d2-4b21-9448-8addbfcbc7a4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Unmount a Mount Point\nUse **`dbutils.fs.unmount`** to unmount a mount point."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63b69ee6-075c-466e-b648-6d347493abbc"}}},{"cell_type":"code","source":["dbutils.fs.unmount(mountPoint)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2c03cd1-a9f9-46d8-92ec-67368eb9e20c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["And for confirmation, let's take a look at all the mounts."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5379baac-18e1-43dd-a118-1806c43aeea2"}}},{"cell_type":"code","source":["display(dbutils.fs.mounts())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a58379a8-c286-47df-9b68-c99d6b9eac74"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69dd4680-d881-4792-bbe6-e1c99fd3c97c"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36a98226-574e-4e4e-91d7-c27f6ce07310"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7d85719-fec2-4237-961b-ea088ea320e0"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"MSA 1 - Blob Storage","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3794944577840565}},"nbformat":4,"nbformat_minor":0}
